%!TEX root = ../dissertation.tex

\chapter{Background}
\label{chp:background}
In questa tesi, il modello che rappresenta i dati in input, a differenza di algoritmi più tradizionali,
è chiamato \emph{modello di stream di dati} (data stream model). 
\section{Modello di stream di dati}
Nel modello di stream i dati \cite{Leskovec_Rajaraman_Ullman_2014} arrivano in modo continuo e potenzialmente
infinita. Rispetto l'utilizzo di un database tradizionale, non è possibile
accumulare tutto in memoria o su disco e interrogare i dati. 
Gli elementi devono essere processati al volo oppure vengono persi.

Inoltre, la velocità con cui i dati arrivano non è controllata dal sistema (più stream
possono arrivare a velocità e con formati diversi) e lo spazio di memoria
disponibile è limitato. Eventuali archivi storici possono esistere, ma non
sono pensati per rispondere a query online in tempi ragionevoli.

Iniziamo a definire formalmente gli elementi di una stream e come vengono processati.
Possiamo considerare una stream come una sequenza di elementi ordinata che arriva uno alla volta, con possibili ripetizioni:
\[
S = \langle x_1, x_2, \dots, x_s \rangle,
\]
dove ogni $x_i$ appartiene a un universo $\mathcal{U}$ molto grande. Per ogni
elemento $a \in \mathcal{U}$ definiamo la frequenza:
\[
f(a) = |\{ i \mid x_i = a \}|.
\]

Uno degli obiettivi principale di questa tesi è stimare la cardinalità dello stream,
ossia il numero di elementi distinti:
\[
F_0 = |\{ a \in \mathcal{U} \mid f(a) > 0 \}|.
\]

Più in generale, dato lo stream $S$ si definiscono i \emph{frequency moments}
\[
F_k = \sum_{a \in \mathcal{U}} f(a)^k,
\]
di cui $F_0$ è il numero di distinti. Queste quantità sono studiate nel modello
di stream proprio per il loro valore statistico e per i vincoli di memoria
sublineare \cite{Alon_Matias_Szegedy_2002}.

Per formalizzare l'accuratezza di uno stimatore si usano due parametri
$(\varepsilon,\delta)$. Un algoritmo $A$ è detto \emph{$(\varepsilon,\delta)$-approssimante}
per $F_0$ se, per ogni stream, produce una stima $\tilde{F}_0$ tale che
\[
\Pr\bigl(|\tilde{F}_0 - F_0| \le \varepsilon F_0\bigr) \ge 1 - \delta,
\]
dove la probabilità è rispetto alla randomizzazione interna dell'algoritmo
\cite{BarYossef_Jayram_Kumar_Sivakumar_Trevisan_2002}.

Supponiamo inoltre che l'universo abbia dimensione $n = |\mathcal{U}|$ e che ogni elemento $x_i$
richieda $b$ bit per essere rappresentato.

In questo contesto, un algoritmo di streaming deve:
\begin{itemize}
    \item processare ciascun elemento con costo $O(1)$ o quasi costante;
    \item usare memoria molto più piccola di $n$ e di $|\mathcal{U}|$;
    \item produrre una stima $\hat{F}_0$ con errore controllato, utilizzando $m$ bits, dove $m \ll n$.
\end{itemize}

Nel modello dello stream dei dati esistono diverse tipologie di modelli
\cite{Muthukrishnan_2005}. In questa tesi adottiamo il modello
\emph{insertion-only} (o \emph{cash register}), in cui lo stream è una sequenza
di aggiornamenti del tipo $(a_t, \Delta_t)$, con $a_t \in \mathcal{U}$ e
$\Delta_t \ge 0$. Indichiamo con $A_t[j]$ la frequenza dell'elemento $j$ dopo
i primi $t$ aggiornamenti; allora
\[
A_t[j] =
\begin{cases}
A_{t-1}[j] + \Delta_t & \text{se } a_t = j,\\
A_{t-1}[j] & \text{altrimenti}.
\end{cases}
\]
Esistono tuttavia modelli più generali, come il \emph{turnstile}, che ammette anche aggiornamenti negativi
($\Delta_t$ può essere negativo), o il modello a \emph{sliding window}, in cui si
considera solo una finestra temporale degli ultimi $W$ elementi. Questi casi
esulano dallo scopo della tesi.

Per rispettare questi vincoli si ricorre a funzioni hash che approssimano
una distribuzione uniforme sugli elementi e a strutture compatte, chiamate \textbf{sketch},
che riassumono le informazioni essenziali dello stream senza conservarlo esplicitamente.

Un esempio di istanza per la stima della cardinalità è lo stream:
\[
S = \langle a, b, a, c, d, b, d \rangle.
\]
In questo caso l'insieme dei distinti è $\{a,b,c,d\}$ e quindi $F_0 = 4$.

\paragraph{Spazio sublineare.}
Nel modello streaming è fondamentale che la memoria utilizzata sia
\emph{sublineare} rispetto alla dimensione dell'universo o alla lunghezza dello stream.
Diremo che un algoritmo usa spazio sublineare se la memoria $m$ cresce
asintoticamente meno di $n$, cioè $m = o(n)$, e in pratica si richiede che
$m$ dipenda in modo polilogaritmico da $n$ e polinomiale da
$1/\varepsilon$ e $\log(1/\delta)$. Questa proprietà è cruciale perché
memorizzare tutti i distinti richiede $\Omega(n)$ bit, mentre nel problema dei
distinti esistono algoritmi che ottengono una $(1 \pm \varepsilon)$-approssimazione
con $O(\varepsilon^{-2} + \log n)$ bit, e questo ordine è ottimale
\cite{Kane_Nelson_Woodruff_2010}. In altre parole, lo sketching rende possibile
stimare quantità globali con memoria molto più piccola di quella necessaria
per conservare i dati grezzi.

\section{Algoritmi di streaming}
In questa sezione si definisce cosa si intende per algoritmo di streaming e
quali vincoli lo distinguono dagli algoritmi tradizionali. Da completare:
\begin{itemize}
    \item Definizione formale di algoritmo di streaming.
    \item Stato compatto $M$ e operazioni:
    \[
    M \leftarrow \mathrm{Update}(M, x), \qquad \hat{F}_0 \leftarrow \mathrm{Query}(M).
    \]
    \item Modello di costo: un passaggio, update $O(1)$, query su stato compatto.
    \item Limiti di memoria e trade-off accuratezza/spazio.
    \item Differenza tra stime in tempo reale e analisi offline.
    \item Randomizzazione e garanzie probabilistiche.
    \item (Definizione) mergeabilità/composability degli sketch.
\end{itemize}

\section{Funzioni hash}
Qui si introduce il ruolo delle funzioni hash nella riduzione dello spazio e
nella randomizzazione delle stime. Da completare:
\begin{itemize}
    \item Definizione di hash e proprietà desiderate.
    \item Modello ideale: $h: \mathcal{U} \to [0,1)$ o $h:\mathcal{U}\to\{0,1\}^w$.
    \item Assunzioni tipiche: uniformità, indipendenza (o hash quasi-uniformi).
    \item Impatto di scelte non ideali sull'errore degli stimatori.
    \item Eventuale gestione del seed per riproducibilità.
\end{itemize}

\section{Sketch}
Si definisce lo sketch come struttura compatta che riassume lo stream. Da completare:
\begin{itemize}
    \item Definizione generale di sketch e operazioni supportate (update, query).
    \item Dimensione dello sketch e relazione con i parametri ($k$, $m$, $L$).
    \item Esempi intuitivi (registri, bitmap, contatori).
    \item Due forme usate in tesi:
    \begin{itemize}
        \item bitmap / pattern di bit (Probabilistic Counting).
        \item registri e leading zeros (LogLog, HLL, HLL++).
    \end{itemize}
    \item (Cenno) serializzabilità e footprint in byte.
\end{itemize}

\section{Stimatori}
Si descrive cosa si intende per stimatore e in che senso la stima è corretta. Da completare:
\begin{itemize}
    \item Definizione di stimatore $\hat{F}_0$ e proprietà desiderate.
    \item Distinzione tra stimatore corretto (unbiased) e stimatore biased.
    \item Consistenza e varianza dello stimatore.
    \item Cenno a tecniche di bias correction.
\end{itemize}

\section{Metriche di errore}
Questa sezione introduce le metriche di qualità della stima. Da completare:
\begin{itemize}
    \item Errore assoluto e relativo.
    \item Bias e unbiased estimator.
    \item Varianza e standard error.
    \item RMSE e MAE come metriche aggregate.
    \item RSE teorica vs osservata (quando applicabile).
    \item Definizioni allineate alle colonne CSV del framework.
\end{itemize}

\section{Famiglia di algoritmi per count-distinct}
Sezione ponte (senza dettagli implementativi) per motivare il Capitolo 3. Da completare:
\begin{itemize}
    \item Baseline esatta vs sketch probabilistici.
    \item Linea FM/Probabilistic Counting $\rightarrow$ LogLog $\rightarrow$ HLL $\rightarrow$ HLL++.
    \item Differenze qualitative: riduzione varianza, correzioni di range, uso di registri.
\end{itemize}

\section{Spazio--accuratezza: ordini di grandezza}
Sezione opzionale ma utile per giustificare l'uso degli sketch. Da completare:
\begin{itemize}
    \item Dipendenza dello spazio da $(\varepsilon,\delta)$.
    \item Interpretazione di ``ottimalità'' a livello di ordine di grandezza.
\end{itemize}
