%!TEX root = ../dissertation.tex

\chapter{Background}
\label{chp:background}
In questa tesi, il modello che rappresenta i dati in input, a differenza di algoritmi più tradizionali,
è chiamato \emph{modello di stream di dati} (data stream model). 
\section{Modello di stream di dati}
Nel modello di stream i dati \cite{Leskovec_Rajaraman_Ullman_2014} arrivano in modo continuo e potenzialmente
infinita. Rispetto l'utilizzo di un database tradizionale, non è possibile
accumulare tutto in memoria o su disco e interrogare i dati. 
Gli elementi devono essere processati al volo oppure vengono persi.

Inoltre, la velocità con cui i dati arrivano non è controllata dal sistema (più stream
possono arrivare a velocità e con formati diversi) e lo spazio di memoria
disponibile è limitato. Eventuali archivi storici possono esistere, ma non
sono pensati per rispondere a query online in tempi ragionevoli.

Iniziamo a definire formalmente gli elementi di una stream e come vengono processati.
\begin{definition}[Stream di dati]
Sia $\mathcal{U}$ un universo di chiavi. Senza perdita di generalità, assumiamo
$\mathcal{U} \subseteq \mathbb{N}$. Una \emph{stream di dati} è una sequenza ordinata
di elementi
\[
S = \langle x_1, x_2, \dots, x_s \rangle,
\]
dove ogni $x_i \in \mathcal{U}$ e $s$ può essere molto grande o non noto a priori.
\end{definition}

Per analizzare una stream è utile descriverla tramite le frequenze degli elementi.
\begin{definition}[Frequenze]
Data una stream $S$, la \emph{frequenza} di un elemento $a \in \mathcal{U}$ è
\[
f(a) = |\{ i \mid x_i = a \}|.
\]
La collezione delle frequenze può essere vista come un vettore $f \in \mathbb{N}^{|\mathcal{U}|}$.
\end{definition}

Una volta definita la nozione di frequenza, si specifica il modello di aggiornamento
con cui la stream viene osservata.
Nel modello della stream dei dati esistono diverse tipologie di modelli
\cite{Muthukrishnan_2005}. In questa tesi adottiamo il seguente.
\begin{definition}[Modello \emph{insertion-only}]
La stream è una sequenza di aggiornamenti del tipo $(a_t, \Delta_t)$, con
$a_t \in \mathcal{U}$ e $\Delta_t \ge 0$. Indichiamo con $A_t[j]$ la frequenza
dell'elemento $j$ dopo i primi $t$ aggiornamenti; allora
\[
A_t[j] =
\begin{cases}
A_{t-1}[j] + \Delta_t & \text{se } a_t = j,\\
A_{t-1}[j] & \text{altrimenti}.
\end{cases}
\]
\end{definition}
Se la stream è una lista di valori, ogni elemento $x_i$ può essere visto come
un aggiornamento $(x_i,1)$.

Esistono tuttavia modelli più generali. Nel \emph{turnstile} sono ammessi
anche aggiornamenti negativi, così che le frequenze possano aumentare o diminuire.
Nel modello a \emph{sliding window} si considerano solo gli ultimi $W$ aggiornamenti
della stream, scartando i più vecchi. Questi casi esulano dallo scopo della tesi,
ma sono citati per completezza.

Fissato il modello, l'obiettivo principale della tesi è stimare la cardinalità
dell'insieme dei distinti.
\begin{definition}[Numero di distinti]
Il \emph{numero di distinti} nella stream $S$ è
\[
F_0 = |\{ a \in \mathcal{U} \mid f(a) > 0 \}|.
\]
\end{definition}

Più in generale, il numero di distinti è un caso particolare di una famiglia
di misure note come \emph{frequency moments}.
\begin{definition}[Frequency moments]
Per ogni $k \ge 0$, il \emph{frequency moment} $F_k$ è definito come
\[
F_k = \sum_{a \in \mathcal{U}} f(a)^k.
\]
In particolare, $F_0$ corrisponde al numero di distinti.
\end{definition}

Per valutare la qualità di una stima si introduce la nozione di approssimazione
con parametri di accuratezza e confidenza.
\begin{definition}[$(\varepsilon,\delta)$-approssimazione]
Un algoritmo $A$ è detto \emph{$(\varepsilon,\delta)$-approssimante} per $F_0$ se, per ogni stream,
produce una stima $\tilde{F}_0$ tale che
\[
\Pr\bigl(|\tilde{F}_0 - F_0| \le \varepsilon F_0\bigr) \ge 1 - \delta,
\]
dove la probabilità è rispetto alla randomizzazione interna dell'algoritmo
\cite{BarYossef_Jayram_Kumar_Sivakumar_Trevisan_2002}.
\end{definition}
\paragraph{Esempio.}
Con $\varepsilon = 0{,}05$ e $\delta = 0{,}01$, l'algoritmo deve restituire una stima
entro il $5\%$ da $F_0$ con probabilità almeno $99\%$.

Supponiamo inoltre che l'universo abbia dimensione $n = |\mathcal{U}|$ e che ogni elemento $x_i$
richieda $b$ bit per essere rappresentato.

Le garanzie di accuratezza devono convivere con vincoli stringenti di tempo e memoria.
In questo contesto, un algoritmo di streaming deve:
\begin{itemize}
    \item processare ciascun elemento con costo $O(1)$ o quasi costante;
    \item usare memoria molto più piccola di $n$ e di $|\mathcal{U}|$;
    \item produrre una stima $\hat{F}_0$ con errore controllato, utilizzando $m$ bits, dove $m \ll n$.
\end{itemize}

Per rispettare questi vincoli si ricorre a funzioni hash che approssimano
una distribuzione uniforme sugli elementi e a strutture compatte, chiamate \textbf{sketch},
che riassumono le informazioni essenziali della stream senza conservarla esplicitamente.

Il vincolo più forte è quello di memoria: si richiede che lo spazio cresca
molto più lentamente della dimensione dell'universo.
\begin{definition}[Spazio sublineare]
Un algoritmo usa \emph{spazio sublineare} se la memoria $m$ cresce
asintoticamente meno di $n$, cioè $m = o(n)$, dove $n = |\mathcal{U}|$.
Si richiede che $m$ dipenda in modo polilogaritmico da $n$ e
polinomiale da $1/\varepsilon$ e $\log(1/\delta)$.
\end{definition}
\paragraph{Esempio.}
Per il problema dei distinti esistono algoritmi che ottengono una
$(1 \pm \varepsilon)$-approssimazione usando $O(\varepsilon^{-2} + \log n)$ bit
\cite{Kane_Nelson_Woodruff_2010}, che è molto meno dei $\Omega(n)$ bit necessari
per memorizzare l'insieme dei distinti.

\section{Algoritmi di streaming}
In questa sezione si definisce cosa si intende per algoritmo di streaming e
quali vincoli lo distinguono dagli algoritmi tradizionali. Da completare:
\begin{itemize}
    \item Definizione formale di algoritmo di streaming.
    \item Stato compatto $M$ e operazioni:
    \[
    M \leftarrow \mathrm{Update}(M, x), \qquad \hat{F}_0 \leftarrow \mathrm{Query}(M).
    \]
    \item Modello di costo: un passaggio, update $O(1)$, query su stato compatto.
    \item Limiti di memoria e trade-off accuratezza/spazio.
    \item Differenza tra stime in tempo reale e analisi offline.
    \item Randomizzazione e garanzie probabilistiche.
    \item (Definizione) mergeabilità/composability degli sketch.
\end{itemize}

\section{Funzioni hash}
Qui si introduce il ruolo delle funzioni hash nella riduzione dello spazio e
nella randomizzazione delle stime. Da completare:
\begin{itemize}
    \item Definizione di hash e proprietà desiderate.
    \item Modello ideale: $h: \mathcal{U} \to [0,1)$ o $h:\mathcal{U}\to\{0,1\}^w$.
    \item Assunzioni tipiche: uniformità, indipendenza (o hash quasi-uniformi).
    \item Impatto di scelte non ideali sull'errore degli stimatori.
    \item Eventuale gestione del seed per riproducibilità.
\end{itemize}

\section{Sketch}
Si definisce lo sketch come struttura compatta che riassume la stream. Da completare:
\begin{itemize}
    \item Definizione generale di sketch e operazioni supportate (update, query).
    \item Dimensione dello sketch e relazione con i parametri ($k$, $m$, $L$).
    \item Esempi intuitivi (registri, bitmap, contatori).
    \item Due forme usate in tesi:
    \begin{itemize}
        \item bitmap / pattern di bit (Probabilistic Counting).
        \item registri e leading zeros (LogLog, HLL, HLL++).
    \end{itemize}
    \item (Cenno) serializzabilità e footprint in byte.
\end{itemize}

\section{Stimatori}
Si descrive cosa si intende per stimatore e in che senso la stima è corretta. Da completare:
\begin{itemize}
    \item Definizione di stimatore $\hat{F}_0$ e proprietà desiderate.
    \item Distinzione tra stimatore corretto (unbiased) e stimatore biased.
    \item Consistenza e varianza dello stimatore.
    \item Cenno a tecniche di bias correction.
\end{itemize}

\section{Metriche di errore}
Questa sezione introduce le metriche di qualità della stima. Da completare:
\begin{itemize}
    \item Errore assoluto e relativo.
    \item Bias e unbiased estimator.
    \item Varianza e standard error.
    \item RMSE e MAE come metriche aggregate.
    \item RSE teorica vs osservata (quando applicabile).
    \item Definizioni allineate alle colonne CSV del framework.
\end{itemize}

\section{Famiglia di algoritmi per count-distinct}
Sezione ponte (senza dettagli implementativi) per motivare il Capitolo 3. Da completare:
\begin{itemize}
    \item Baseline esatta vs sketch probabilistici.
    \item Linea FM/Probabilistic Counting $\rightarrow$ LogLog $\rightarrow$ HLL $\rightarrow$ HLL++.
    \item Differenze qualitative: riduzione varianza, correzioni di range, uso di registri.
\end{itemize}

\section{Spazio--accuratezza: ordini di grandezza}
Sezione opzionale ma utile per giustificare l'uso degli sketch. Da completare:
\begin{itemize}
    \item Dipendenza dello spazio da $(\varepsilon,\delta)$.
    \item Interpretazione di ``ottimalità'' a livello di ordine di grandezza.
\end{itemize}
