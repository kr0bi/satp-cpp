%!TEX root = ../dissertation.tex

\chapter{Background}
\label{chp:background}
In questa tesi, il modello che rappresenta i dati in input, a differenza di algoritmi più tradizionali,
è chiamato \emph{modello di stream di dati} (data stream model). 
\section{Modello di stream di dati}
Nel modello di stream i dati \cite{Leskovec_Rajaraman_Ullman_2014} arrivano in modo continuo e potenzialmente
infinita. Rispetto l'utilizzo di un database tradizionale, non è possibile
accumulare tutto in memoria o su disco e interrogare i dati. 
Gli elementi devono essere processati al volo oppure vengono persi.

Inoltre, la velocità con cui i dati arrivano non è controllata dal sistema (più stream
possono arrivare a velocità e con formati diversi) e lo spazio di memoria
disponibile è limitato. Eventuali archivi storici possono esistere, ma non
sono pensati per rispondere a query online in tempi ragionevoli.

Iniziamo a definire formalmente gli elementi di una stream e come vengono processati.
\begin{definition}[Stream di dati]
Sia $\mathcal{U}$ un universo di chiavi. Senza perdita di generalità, assumiamo
$\mathcal{U} \subseteq \mathbb{N}$. Una \emph{stream di dati} è una sequenza ordinata
di elementi
\[
S = \langle x_1, x_2, \dots, x_s \rangle,
\]
dove ogni $x_i \in \mathcal{U}$ e $s$ può essere molto grande o non noto a priori.
\end{definition}

Per analizzare una stream è utile descriverla tramite le frequenze degli elementi.
\begin{definition}[Frequenze]
Data una stream $S$, la \emph{frequenza} di un elemento $a \in \mathcal{U}$ è
\[
f(a) = |\{ i \mid x_i = a \}|.
\]
La collezione delle frequenze può essere vista come un vettore $f \in \mathbb{N}^{|\mathcal{U}|}$.
\end{definition}

Una volta definita la nozione di frequenza, si specifica il modello di aggiornamento
con cui la stream viene osservata.
Nel modello della stream dei dati esistono diverse tipologie di modelli
\cite{Muthukrishnan_2005}. In questa tesi adottiamo il seguente.
\begin{definition}[Modello \emph{insertion-only}]
La stream è una sequenza di aggiornamenti del tipo $(a_t, \Delta_t)$, con
$a_t \in \mathcal{U}$ e $\Delta_t \ge 0$. Indichiamo con $A_t[j]$ la frequenza
dell'elemento $j$ dopo i primi $t$ aggiornamenti; allora
\[
A_t[j] =
\begin{cases}
A_{t-1}[j] + \Delta_t & \text{se } a_t = j,\\
A_{t-1}[j] & \text{altrimenti}.
\end{cases}
\]
\end{definition}
Se la stream è una lista di valori, ogni elemento $x_i$ può essere visto come
un aggiornamento $(x_i,1)$.

Esistono tuttavia modelli più generali. Nel \emph{turnstile} sono ammessi
anche aggiornamenti negativi, così che le frequenze possano aumentare o diminuire.
Nel modello a \emph{sliding window} si considerano solo gli ultimi $W$ aggiornamenti
della stream, scartando i più vecchi. Questi casi esulano dallo scopo della tesi,
ma sono citati per completezza.

Fissato il modello, l'obiettivo principale della tesi è stimare la cardinalità
dell'insieme dei distinti.
\begin{definition}[Numero di distinti]
Il \emph{numero di distinti} nella stream $S$ è
\[
F_0 = |\{ a \in \mathcal{U} \mid f(a) > 0 \}|.
\]
\end{definition}

Più in generale, il numero di distinti è un caso particolare di una famiglia
di misure note come \emph{frequency moments}.
\begin{definition}[Frequency moments]
Per ogni $k \ge 0$, il \emph{frequency moment} $F_k$ è definito come
\[
F_k = \sum_{a \in \mathcal{U}} f(a)^k.
\]
In particolare, $F_0$ corrisponde al numero di distinti.
\end{definition}

Per valutare la qualità di una stima si introduce la nozione di approssimazione
con parametri di accuratezza e confidenza.
\begin{definition}[$(\varepsilon,\delta)$-approssimazione]
Un algoritmo $A$ è detto \emph{$(\varepsilon,\delta)$-approssimante} per $F_0$ se, per ogni stream,
produce una stima $\tilde{F}_0$ tale che
\[
\Pr\bigl(|\tilde{F}_0 - F_0| \le \varepsilon F_0\bigr) \ge 1 - \delta,
\]
dove la probabilità è rispetto alla randomizzazione interna dell'algoritmo
\cite{BarYossef_Jayram_Kumar_Sivakumar_Trevisan_2002}.
\end{definition}
\paragraph{Esempio.}
Con $\varepsilon = 0{,}05$ e $\delta = 0{,}01$, l'algoritmo deve restituire una stima
entro il $5\%$ da $F_0$ con probabilità almeno $99\%$.

Supponiamo inoltre che l'universo abbia dimensione $n = |\mathcal{U}|$ e che ogni elemento $x_i$
richieda $b$ bit per essere rappresentato.

Le garanzie di accuratezza devono convivere con vincoli stringenti di tempo e memoria.
In questo contesto, un algoritmo di streaming deve:
\begin{itemize}
    \item processare ciascun elemento con costo $O(1)$ o quasi costante;
    \item usare memoria molto più piccola di $n$ e di $|\mathcal{U}|$;
    \item produrre una stima $\hat{F}_0$ con errore controllato, utilizzando $m$ bits, dove $m \ll n$.
\end{itemize}

Per rispettare questi vincoli si ricorre a funzioni hash che approssimano
una distribuzione uniforme sugli elementi e a strutture compatte, chiamate \textbf{sketch},
che riassumono le informazioni essenziali della stream senza conservarla esplicitamente.

Il vincolo più forte è quello di memoria: si richiede che lo spazio cresca
molto più lentamente della dimensione dell'universo.
\begin{definition}[Spazio sublineare]
Un algoritmo usa \emph{spazio sublineare} se la memoria $m$ cresce
asintoticamente meno di $n$, cioè $m = o(n)$, dove $n = |\mathcal{U}|$.
Si richiede che $m$ dipenda in modo polilogaritmico da $n$ e
polinomiale da $1/\varepsilon$ e $\log(1/\delta)$.
\end{definition}
\paragraph{Esempio.}
Per il problema dei distinti esistono algoritmi che ottengono una
$(1 \pm \varepsilon)$-approssimazione usando $O(\varepsilon^{-2} + \log n)$ bit
\cite{Kane_Nelson_Woodruff_2010}, che è molto meno dei $\Omega(n)$ bit necessari
per memorizzare l'insieme dei distinti.

\section{Algoritmi di streaming}
Il modello di data stream, con le caratteristiche appena descritte---flussi potenzialmente infiniti, velocità
non controllata e memoria limitata---rende inapplicabili gli approcci
classici basati su memorizzazione completa e analisi a posteriori.

Gli algoritmi di streaming nascono per produrre stime e
statistiche utili durante l'arrivo dei dati, lavorando in un solo passaggio e
mantenendo una sintesi compatta della stream.
\begin{definition}[Algoritmo di streaming]
Un algoritmo di streaming elabora una stream in un solo passaggio e mantiene
uno stato interno $M$ di dimensione limitata $m$. Per ogni elemento $x_i$ della
stream, lo stato viene aggiornato tramite una funzione
\[
M \leftarrow \mathrm{Update}(M, x_i),
\]
e in qualunque momento è possibile ottenere una risposta (o stima) tramite
\[
\hat{F}_0 \leftarrow \mathrm{Query}(M).
\]
Nel modello classico si richiede che $m$ sia sublineare rispetto a $n$ e che
il tempo per aggiornamento sia $O(1)$ o quasi costante \cite{Muthukrishnan_2005}.
\end{definition}

Dopo ogni aggiornamento, l'elemento appena osservato
può essere scartato: lo stato $M$ rappresenta una sintesi compatta dei dati,
spesso chiamata \emph{sketch} \cite{Cormode_2017}.

Da questa definizione derivano i criteri con cui si
valutano le prestazioni: nel modello classico si
misurano in termini di \textbf{passaggi} sulla stream, \textbf{memoria} usata,
\textbf{tempo per elemento} e \textbf{accuratezza} della risposta. Per algoritmi
di approssimazione, l'accuratezza è espressa tramite un rapporto di
approssimazione e una probabilità di successo, spesso nel modello
$(\varepsilon,\delta)$ \cite{Prezza_2025}.

Esiste una tipologia di algoritmi, chiamata algoritmi \textit{online} che sono molto simili \cite{OnlineAlgorithms_Notes}, perché
operano senza disporre dell'intero input; tuttavia non sono identici, poiché nel
modello streaming è possibile talvolta differire l'azione fino all'arrivo di
piccoli blocchi di elementi, pur mantenendo una memoria molto limitata
\cite{Muthukrishnan_2005,Prezza_2025}. Un possibile esempio è fornito dagli
algoritmi per la \emph{sliding window}, che mantengono riassunti a blocchi per
stimare statistiche recenti con memoria limitata
\cite{Datar_Gionis_Indyk_Motwani_2002}. Nel nostro contesto, tutti gli algoritmi
implementati e trattati sono anche \emph{online}, perché processano ogni elemento
appena arriva, senza differire l'azione.

Nel contesto degli algoritmi di streaming, un tema centrale è il
trade-off tra precisione e memoria. Per il problema del calcolo degli elementi distinti, la
letteratura evidenzia un legame diretto tra accuratezza e spazio: ridurre
$\varepsilon$ implica un incremento della memoria necessaria. In particolare, si
considerano efficienti gli algoritmi che usano solo spazio polinomiale in
$1/\varepsilon$ e logaritmico nella lunghezza della stream e nella dimensione
dell'universo, con un costo per elemento molto basso
\cite{BarYossef_Jayram_Kumar_Sivakumar_Trevisan_2002}. Questo mette in evidenza
il \textbf{trade-off} centrale tra precisione e spazio necessario dello sketch.

Questi algoritmi sono spesso randomizzati: la probabilità nella definizione di $(\varepsilon,\delta)$
è rispetto alle scelte casuali interne dell'algoritmo e rappresenta una
garanzia probabilistica sulla qualità della stima
\cite{BarYossef_Jayram_Kumar_Sivakumar_Trevisan_2002}. Nelle implementazioni
pratiche, questa randomizzazione è tipicamente incarnata dalla funzione di hash,
assunta sufficientemente vicina a una scelta casuale (o parametrizzata da un
seed). La randomizzazione consente di ridurre drasticamente lo spazio rispetto
alle soluzioni deterministiche, a patto di accettare un errore controllato con
alta probabilità.

Un'altra differenza rilevante rispetto all'analisi tradizionale è la distinzione tra stime in tempo reale e analisi
\emph{offline}. Nei sistemi classici, gli aggiornamenti si registrano in un
archivio e le analisi complesse vengono svolte in \emph{warehouse}. Nel modello
di streaming, invece, molte applicazioni richiedono elaborazioni sofisticate in
quasi tempo reale, come rilevamento di anomalie, monitoraggio di trend o
cambiamenti improvvisi, e questo condiziona la progettazione degli algoritmi
\cite{Muthukrishnan_2005}.

\`E importante notare che in contesti distribuiti è spesso necessario combinare
riassunti di porzioni diverse della stream. Il concetto di \emph{mergeabilità}
formalizza la possibilità di unire due sintesi in una sintesi della loro unione
preservando le garanzie di errore e la dimensione dello stato: questo permette
di scalare gli algoritmi a scenari paralleli o gerarchici ed è una proprietà
centrale per gli sketch moderni \cite{Agarwal_Cormode_Huang_Phillips_Wei_Yi_2012}.

\section{Funzioni di hash}
Le funzioni hash sono il principale strumento per
``randomizzare'' lo stream e associare un universo molto grande in un dominio più
piccolo, rendendo possibile l'uso di strutture compatte. In molti sketch, la
qualità della stima dipende direttamente dalle proprietà della funzione di hash utilizzata
\cite{Vadhan_Mitzenmacher_2007,UniformHashing_Pagh_2007}.

\begin{definition}[Funzione di hash]
Una funzione di hash $h$ è una funzione deterministica
\[
h: \mathcal{U} \to V,
\]
che associa a ogni chiave dell'universo $\mathcal{U}$ un valore in un
dominio $V$ di dimensione molto più piccola, tipicamente $V=\{0,1\}^w$ oppure
$V=[0,1)$ tramite normalizzazione.
\end{definition}

Quindi, una funzione di hash mappa dati di lunghezza
arbitraria in un valore di lunghezza fissa, chiamato \emph{hash value}, 
spesso usato per indicizzare delle strutture dati come le tabelle di hash.

Questa trasformazione permette accessi veloci e riduce lo spazio necessario
rispetto alla memorizzazione diretta delle chiavi. 

Poiché più chiavi possono
produrre lo stesso valore, le \emph{collisioni} sono inevitabili: una buona
funzione di hash deve essere veloce da calcolare e minimizzare la probabilità
di collisione, idealmente distribuendo i valori in modo uniforme sul dominio
\cite{Wikipedia_HashFunction}.

\textit{Proprietà desiderate.} Le proprietà classiche richieste sono: l'\textbf{uniformità} 
(le chiavi sono distribuite in modo uniforme su $V$), la
\textbf{bassa probabilità di collisione}, l'\textbf{indipendenza} tra le immagini di
chiavi diverse e l'\textbf{efficienza} di calcolo. 

Una funzione di hash con queste proprietà rende la stima degli sketch stabili e con varianza controllata
\cite{Vadhan_Mitzenmacher_2007,UniformHashing_Pagh_2007}.

\begin{definition}[Modello di hashing uniforme]
Nel modello ideale, $h$ è scelta uniformemente a caso dall'insieme di tutte le
funzioni $\mathcal{U}\to V$. In questo caso, per ogni chiave $x\in\mathcal{U}$,
il valore $h(x)$ è uniforme in $V$ e le immagini di chiavi distinte sono
indipendenti \cite{Vadhan_Mitzenmacher_2007,UniformHashing_Pagh_2007}.
\end{definition}

\begin{definition}[Famiglia universale \cite{Carter_Wegman_1979}]
Una famiglia $\mathcal{H}$ di funzioni $\mathcal{U}\to V$ è \emph{universale} se,
per ogni coppia di chiavi distinte $x\neq y$, vale
\[
\Pr_{h\leftarrow \mathcal{H}}\bigl[h(x)=h(y)\bigr] \le \frac{1}{|V|}.
\]
\end{definition}

\begin{definition}[$k$-wise indipendenza \cite{Vadhan_Mitzenmacher_2007}]
Una famiglia $\mathcal{H}$ è \emph{$k$-wise indipendente} se, per ogni scelta di
$k$ chiavi distinte $x_1,\dots,x_k$, il vettore
\[
\bigl(h(x_1),\dots,h(x_k)\bigr)
\]
è distribuito uniformemente in $V^k$ quando $h$ è scelta a caso da $\mathcal{H}$.
\end{definition}

\textit{Assunzioni tipiche.} Nelle analisi teoriche si assume spesso il modello
ideale di hashing uniforme; in alternativa si usa una famiglia con un grado
limitato di indipendenza (ad esempio $k$-wise), o una famiglia universale
\cite{Carter_Wegman_1979,Vadhan_Mitzenmacher_2007}. In pratica, l'uso di
funzioni semplici è comune, ma le garanzie possono degradare rispetto al modello
ideale se le assunzioni non sono soddisfatte.

\textit{Impatto delle scelte.} Una funzione di hash non sufficientemente uniforme può
introdurre collisioni sistematiche o correlazioni tra registri, con un aumento
del bias e della varianza degli stimatori \cite{Vadhan_Mitzenmacher_2007,UniformHashing_Pagh_2007}.

\section{Sketch}
\label{sec:sketch}
Uno \emph{sketch} è una struttura dati probabilistica che
riassume una stream attraverso uno stato $M$ aggiornabile con operazioni
\emph{update} e interrogabile con operazioni \emph{query}. Lo sketch non conserva
gli elementi originali, ma solo le informazioni necessarie per stimare una
quantità d'interesse con memoria limitata che deve essere molto inferiore rispetto a conservare i dati originali.

Come accennato prima negli algoritmi di streaming, nei contesti distribuiti, per ottenere un dato
globale è necessario poter combinare due
sketch costruiti su porzioni diverse della stream. Come possibile esempio, si pensi a due server che creano in maniera
indipendente la loro sketch dei dati e che si voglia unire queste informazioni. Intuitivamente, ciò è
possibile solo se gli sketch condividono gli stessi parametri strutturali e la stessa funzione di hash
(o lo stesso seed), altrimenti la fusione può degradare le garanzie.
\begin{definition}[Sketch mergeable]
Sia $S(\cdot)$ la procedura che costruisce uno sketch e sia $\oplus$ un
operatore sullo stato. Lo sketch è \emph{mergeable} se, per due dataset
$D_1, D_2$ costruiti con la stessa parametrizzazione e la stessa hash,
vale
\[
S(D_1) \oplus S(D_2) \approx S(D_1 \cup D_2),
\]
preservando le garanzie di errore (o con degradazione nota) \cite{Agarwal_Cormode_Huang_Phillips_Wei_Yi_2012}.
\end{definition}

\begin{definition}[Operatore chiuso]
Sia $\mathcal{S}$ lo spazio degli stati di uno sketch. Un operatore
$\oplus$ è \emph{chiuso} se
\[
\oplus:\mathcal{S}\times\mathcal{S}\to\mathcal{S},
\]
cioè se la combinazione di due stati produce ancora uno stato valido dello
stesso tipo.
\end{definition}

In pratica, l'operatore $\oplus$ deve essere \emph{chiuso} sullo stato
(ad esempio utilizzando la funzione di  massimo per registro o la funzione di somma per componente) e, per aggregazioni
robuste, è preferibile che sia \emph{commutativo} e \emph{associativo};
in molti casi è utile anche l'\emph{idempotenza} per tollerare duplicazioni.

\textit{Osservazione: } Per gli algoritmi che vedremo in seguito, se due sketch hanno gli
stessi parametri e la stessa funzione di hash/seed, lo sketch che si ottiene ``unendo'' registro per registro è equivalente allo sketch costruito sulla
concatenazione (o unione) delle due stream.

\section{Stimatori}
In statistica, uno \emph{stimatore} è una funzione dei
dati osservati che restituisce una stima di un parametro d'interesse. Nel
contesto dello streaming dei dati, la stima dipende sia dalla stream osservata sia dalla
randomizzazione interna dell'algoritmo (ad esempio la funzione di hash)
\cite{VanDeGeer_2015}.

Adesso andremo a definire alcuni concetti essenziali affinché sia possibile valutare la qualità di una stima e confrontare diversi algoritmi.

\begin{definition}[Stimatore]
Sia $\theta$ un parametro d'interesse e siano $X$ i dati osservati. Uno
\emph{stimatore} è una funzione misurabile $T$ tale che
\[
\hat{\theta} = T(X),
\]
dove $\hat{\theta}$ è una variabile aleatoria \cite{VanDeGeer_2015}.
\end{definition}

\begin{definition}[Bias e correttezza]
Il \emph{bias} di uno stimatore è
\[
\mathrm{bias}(\hat{\theta}) = \mathbb{E}[\hat{\theta}] - \theta.
\]
Lo stimatore è \emph{corretto} (unbiased) se il bias è nullo; altrimenti è
\emph{biased} \cite{VanDeGeer_2015}.
\end{definition}

Un bias positivo indica una tendenza sistematica a sovrastimare il valore vero,
mentre un bias negativo indica una sottostima. Un bias nullo non garantisce
stima precisa in ogni run, ma elimina lo spostamento medio.

\begin{definition}[Varianza ed errore standard]
La \emph{varianza} di uno stimatore è
\[
\mathrm{Var}(\hat{\theta}) = \mathbb{E}\bigl[(\hat{\theta}-\mathbb{E}[\hat{\theta}])^2\bigr],
\]
mentre l'\emph{errore standard} è la sua radice quadrata
\(\mathrm{SE}(\hat{\theta})=\sqrt{\mathrm{Var}(\hat{\theta})}\)
\cite{VanDeGeer_2015}.
\end{definition}

La varianza descrive quanto le stime oscillano tra esecuzioni: valori piccoli
indicano stabilità, valori grandi indicano dispersione. L'errore standard è
una misura nella stessa unità di $\theta$ e fornisce una scala naturale della
variabilità.

\begin{definition}[Errore di stima e rischio]
L'\emph{errore di stima} è la variabile aleatoria
\[
E = \hat{\theta} - \theta.
\]
Dato una funzione di \emph{loss} $L(E)$, il \emph{rischio} (o rischio atteso) è
\[
R(\hat{\theta}) = \mathbb{E}[L(E)].
\]
Delle scelte comuni per la funzione di loss sono $L(E)=|E|$ (rischio assoluto) e $L(E)=E^2$ (MSE)
\cite{VanDeGeer_2015}.
\end{definition}

L'errore di stima misura lo scostamento puntuale dalla verità, mentre il
rischio riassume l'errore atteso secondo una loss scelta. Loss diverse
privilegiano aspetti diversi: l'errore assoluto è più robusto, l'errore
quadratico penalizza maggiormente gli scostamenti grandi.

\begin{definition}[MAE e MSE]
Il \emph{Mean Absolute Error} (MAE) è
\[
\mathrm{MAE} = \mathbb{E}\bigl[|\hat{\theta}-\theta|\bigr],
\]
mentre il \emph{Mean Squared Error} (MSE) è
\[
\mathrm{MSE} = \mathbb{E}\bigl[(\hat{\theta}-\theta)^2\bigr].
\]
Il MAE misura l'errore medio assoluto, mentre l'MSE penalizza maggiormente
gli errori grandi \cite{VanDeGeer_2015}.
\end{definition}

Il MAE è facilmente interpretabile come distanza media dalla verità. L'MSE (e
la sua radice, l'RMSE) enfatizza gli errori grandi e quindi è sensibile a
outlier o code pesanti nelle stime.

\begin{definition}[Errore relativo]
L'\emph{errore relativo} è definito come
\[
\mathrm{RE} = \frac{|\hat{\theta}-\theta|}{|\theta|},
\]
quando $\theta \neq 0$.
\end{definition}

L'errore relativo normalizza lo scarto rispetto alla grandezza del vero valore
e rende confrontabili stime su dataset di scala diversa.

\begin{definition}[Consistenza]
Una sequenza di stimatori $\hat{\theta}_n$ è \emph{consistente} se
\[
\hat{\theta}_n \xrightarrow[]{P} \theta \quad \text{quando } n \to \infty,
\]
ossia se la stima converge al valore vero al crescere della quantità di
informazione disponibile \cite{VanDeGeer_2015}.
\end{definition}

Nei capitoli successivi, si parlerà della \textbf{bias correction}, in molti sketch si applicano correzioni per
ridurre il bias, ad esempio tramite calibrazione empirica o aggiustamenti
analitici delle formule di stima. Queste tecniche non eliminano necessariamente
la varianza, ma migliorano l'accuratezza media della stima.

\section{Metriche di errore}
Questa sezione definisce le metriche usate per valutare empiricamente gli
stimatori del Capitolo~2.5. Consideriamo $R$ esecuzioni indipendenti
(run), con stime $\hat{F}_0^{(r)}$ e valori veri $F_0^{(r)}$.

\begin{definition}[Metriche empiriche]
Definiamo le seguenti quantità:
\[
\bar{F}_0 = \frac{1}{R}\sum_{r=1}^{R} F_0^{(r)}, \qquad
\bar{\hat{F}}_0 = \frac{1}{R}\sum_{r=1}^{R} \hat{F}_0^{(r)}.
\]
La \emph{varianza campionaria} delle stime è
\[
\mathrm{Var} = \frac{1}{R-1}\sum_{r=1}^{R}\bigl(\hat{F}_0^{(r)}-\bar{\hat{F}}_0\bigr)^2,
\qquad
\mathrm{Stddev}=\sqrt{\mathrm{Var}}.
\]
Il \emph{bias osservato} è
\[
\mathrm{bias} = \bar{\hat{F}}_0 - \bar{F}_0,
\qquad
\mathrm{difference}=|\mathrm{bias}|.
\]
Il \emph{bias relativo} è
\[
\mathrm{bias\_relative}=\frac{\mathrm{bias}}{\bar{F}_0},
\]
quando $\bar{F}_0 \neq 0$.
L'\emph{errore relativo medio} e le metriche aggregate sono
\[
\mathrm{mean\_relative\_error}=\frac{1}{R}\sum_{r=1}^{R}\frac{|\hat{F}_0^{(r)}-F_0^{(r)}|}{F_0^{(r)}},
\]
\[
\mathrm{MAE}=\frac{1}{R}\sum_{r=1}^{R}|\hat{F}_0^{(r)}-F_0^{(r)}|,
\qquad
\mathrm{RMSE}=\sqrt{\frac{1}{R}\sum_{r=1}^{R}\bigl(\hat{F}_0^{(r)}-F_0^{(r)}\bigr)^2}.
\]
Infine, definiamo l'\emph{RSE osservata} come
\[
\mathrm{RSE}_{\text{obs}}=\frac{\mathrm{Stddev}}{\bar{F}_0}.
\]
\end{definition}

Le metriche sopra sono stime empiriche delle quantità teoriche definite nella
sezione precedente. In particolare, il bias osservato approssima il bias
teorico, mentre varianza e RMSE quantificano la dispersione e l'accuratezza
media delle stime su più run. Quando disponibile, si confronta l'RSE osservata
con un valore \emph{RSE teorico} derivato dalla letteratura (ad esempio una
formula del tipo $c/\sqrt{m}$ per HLL), utile per verificare la coerenza tra
risultati sperimentali e predizioni teoriche.

\section{Famiglia di algoritmi per count-distinct}
Sezione ponte (senza dettagli implementativi) per motivare il Capitolo 3. Da completare:
\begin{itemize}
    \item Baseline esatta vs sketch probabilistici.
    \item Linea FM/Probabilistic Counting $\rightarrow$ LogLog $\rightarrow$ HLL $\rightarrow$ HLL++.
    \item Differenze qualitative: riduzione varianza, correzioni di range, uso di registri.
\end{itemize}

\section{Spazio--accuratezza: ordini di grandezza}
Sezione opzionale ma utile per giustificare l'uso degli sketch. Da completare:
\begin{itemize}
    \item Dipendenza dello spazio da $(\varepsilon,\delta)$.
    \item Interpretazione di ``ottimalità'' a livello di ordine di grandezza.
\end{itemize}
