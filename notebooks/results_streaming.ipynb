{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SATP Results - Modalita Streaming\n",
        "\n",
        "Notebook ottimizzato per dataset grandi: lettura a chunk e riduzione su bin di progresso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "RESULTS_PATH = Path('..').resolve() / 'results.csv'\n",
        "BINS = 400\n",
        "\n",
        "metrics = [\n",
        "    'f0_mean','f0_hat_mean','bias','difference','variance','stddev','rmse','mae',\n",
        "    'mean_relative_error','bias_relative','rse_observed'\n",
        "]\n",
        "keys = ['algorithm','sample_size','distinct_count','seed','progress_bin']\n",
        "usecols = ['mode','algorithm','sample_size','distinct_count','seed','element_index'] + metrics\n",
        "\n",
        "sum_acc = None\n",
        "cnt_acc = None\n",
        "\n",
        "for chunk in pd.read_csv(RESULTS_PATH, usecols=usecols, chunksize=300_000):\n",
        "    s = chunk[chunk['mode'] == 'streaming'].copy()\n",
        "    if s.empty:\n",
        "        continue\n",
        "    s['sample_size'] = pd.to_numeric(s['sample_size'], errors='coerce')\n",
        "    s['element_index'] = pd.to_numeric(s['element_index'], errors='coerce')\n",
        "    for m in metrics:\n",
        "        s[m] = pd.to_numeric(s[m], errors='coerce')\n",
        "\n",
        "    progress = s['element_index'] / s['sample_size']\n",
        "    s['progress_bin'] = np.rint(progress * BINS).clip(0, BINS).astype(int)\n",
        "\n",
        "    gb = s.groupby(keys, observed=True)\n",
        "    sums = gb[metrics].sum(min_count=1)\n",
        "    cnts = gb.size().astype(float)\n",
        "\n",
        "    sum_acc = sums if sum_acc is None else sum_acc.add(sums, fill_value=0.0)\n",
        "    cnt_acc = cnts if cnt_acc is None else cnt_acc.add(cnts, fill_value=0.0)\n",
        "\n",
        "if sum_acc is None:\n",
        "    raise RuntimeError('Nessuna riga streaming trovata in results.csv')\n",
        "\n",
        "reduced = sum_acc.div(cnt_acc, axis=0).reset_index()\n",
        "reduced['progress'] = reduced['progress_bin'] / BINS\n",
        "reduced['element_index_est'] = (reduced['progress'] * reduced['sample_size']).round().clip(lower=1).astype(int)\n",
        "\n",
        "print('results:', RESULTS_PATH)\n",
        "print('rows reduced:', len(reduced))\n",
        "print('sample sizes:', sorted(reduced['sample_size'].dropna().unique().tolist()))\n",
        "print('algorithms:', sorted(reduced['algorithm'].dropna().unique().tolist()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Metriche vs progress_bin, con pannelli per sample_size\n",
        "plot_metrics = [\n",
        "    'f0_hat_mean','bias','difference','variance','stddev','rmse','mae',\n",
        "    'mean_relative_error','bias_relative','rse_observed'\n",
        "]\n",
        "sizes = sorted(reduced['sample_size'].unique())\n",
        "algos = sorted(reduced['algorithm'].unique())\n",
        "\n",
        "def plot_facets(metric):\n",
        "    n = len(sizes)\n",
        "    ncols = 3\n",
        "    nrows = math.ceil(n / ncols)\n",
        "    fig, axes = plt.subplots(nrows, ncols, figsize=(5*ncols, 3.6*nrows), squeeze=False)\n",
        "    for idx, size in enumerate(sizes):\n",
        "        r = idx // ncols\n",
        "        c = idx % ncols\n",
        "        ax = axes[r][c]\n",
        "        ss = reduced[reduced['sample_size'] == size].sort_values('progress')\n",
        "        for algo in algos:\n",
        "            g = ss[ss['algorithm'] == algo]\n",
        "            ax.plot(g['progress'], g[metric], label=algo)\n",
        "        ax.set_title(f'sample_size={int(size)}')\n",
        "        ax.set_xlabel('progress (t / sample_size)')\n",
        "        ax.set_ylabel(metric)\n",
        "    for idx in range(len(sizes), nrows*ncols):\n",
        "        r = idx // ncols\n",
        "        c = idx % ncols\n",
        "        axes[r][c].axis('off')\n",
        "    handles, labels = axes[0][0].get_legend_handles_labels()\n",
        "    fig.legend(handles, labels, loc='upper center', ncol=4)\n",
        "    fig.suptitle(f'Streaming: {metric} vs progress', y=1.02, fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "for m in plot_metrics:\n",
        "    plot_facets(m)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dettaglio sul sample_size massimo (asse x log)\n",
        "max_size = int(reduced['sample_size'].max())\n",
        "rmax = reduced[reduced['sample_size'] == max_size].sort_values('element_index_est')\n",
        "\n",
        "for m in plot_metrics:\n",
        "    fig, ax = plt.subplots(figsize=(8.5, 4.8))\n",
        "    for algo in algos:\n",
        "        g = rmax[rmax['algorithm'] == algo]\n",
        "        ax.plot(g['element_index_est'], g[m], label=algo)\n",
        "    ax.set_xscale('log')\n",
        "    ax.set_xlabel('element_index (t, stimato da bin)')\n",
        "    ax.set_ylabel(m)\n",
        "    ax.set_title(f'Streaming (sample_size={max_size}): {m} vs element_index')\n",
        "    ax.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Consistenza con normal alla fine stream (progress_bin == BINS)\n",
        "def load_mode_rows(path: Path, mode: str, usecols, chunksize: int = 250_000) -> pd.DataFrame:\n",
        "    parts = []\n",
        "    for chunk in pd.read_csv(path, usecols=usecols, chunksize=chunksize):\n",
        "        sub = chunk[chunk['mode'] == mode]\n",
        "        if not sub.empty:\n",
        "            parts.append(sub.copy())\n",
        "    if not parts:\n",
        "        return pd.DataFrame(columns=usecols)\n",
        "    return pd.concat(parts, ignore_index=True)\n",
        "\n",
        "cmp_metrics = ['f0_hat_mean','bias','rmse','mae','mean_relative_error','rse_observed']\n",
        "join_cols = ['algorithm','sample_size','distinct_count','seed']\n",
        "\n",
        "normal_usecols = ['mode'] + join_cols + cmp_metrics\n",
        "normal = load_mode_rows(RESULTS_PATH, 'normal', normal_usecols)\n",
        "for c in ['sample_size','distinct_count','seed'] + cmp_metrics:\n",
        "    normal[c] = pd.to_numeric(normal[c], errors='coerce')\n",
        "\n",
        "stream_last = reduced[reduced['progress_bin'] == BINS][join_cols + cmp_metrics].copy()\n",
        "merged = normal[join_cols + cmp_metrics].merge(stream_last, on=join_cols, suffixes=('_normal','_stream_last'))\n",
        "\n",
        "display(merged.head(20))\n",
        "\n",
        "for m in cmp_metrics:\n",
        "    fig, ax = plt.subplots(figsize=(6.2, 5.8))\n",
        "    for algo in sorted(merged['algorithm'].unique()):\n",
        "        g = merged[merged['algorithm'] == algo]\n",
        "        ax.scatter(g[f'{m}_normal'], g[f'{m}_stream_last'], label=algo)\n",
        "    mn = min(merged[f'{m}_normal'].min(), merged[f'{m}_stream_last'].min())\n",
        "    mx = max(merged[f'{m}_normal'].max(), merged[f'{m}_stream_last'].max())\n",
        "    ax.plot([mn, mx], [mn, mx], 'k--', linewidth=1, label='y=x')\n",
        "    ax.set_xlabel(f'{m} (normal)')\n",
        "    ax.set_ylabel(f'{m} (stream_last)')\n",
        "    ax.set_title(f'Consistency: {m} normal vs stream_last')\n",
        "    ax.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}