{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SATP Results - Modalita Normal\n",
    "\n",
    "Grafici inline delle metriche aggregate per run (`mode=normal`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Enable interactive matplotlib toolbar (zoom/pan on both axes)\n",
    "try:\n",
    "    from IPython import get_ipython\n",
    "    ip = get_ipython()\n",
    "    if ip is not None:\n",
    "        try:\n",
    "            ip.run_line_magic('matplotlib', 'widget')\n",
    "        except Exception:\n",
    "            ip.run_line_magic('matplotlib', 'notebook')\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "RESULTS_PATH = Path('..').resolve() / 'results.csv'\n",
    "\n",
    "def load_mode_rows(path: Path, mode: str, usecols, chunksize: int = 250_000) -> pd.DataFrame:\n",
    "    parts = []\n",
    "    for chunk in pd.read_csv(path, usecols=usecols, chunksize=chunksize):\n",
    "        sub = chunk[chunk['mode'] == mode]\n",
    "        if not sub.empty:\n",
    "            parts.append(sub.copy())\n",
    "    if not parts:\n",
    "        return pd.DataFrame(columns=usecols)\n",
    "    return pd.concat(parts, ignore_index=True)\n",
    "\n",
    "metric_cols = [\n",
    "    'f0_mean','f0_hat_mean','mean','variance','stddev','rse_theoretical','rse_observed',\n",
    "    'bias','difference','bias_relative','mean_relative_error','rmse','mae'\n",
    "]\n",
    "usecols = ['algorithm','params','mode','runs','sample_size','element_index','distinct_count','seed'] + metric_cols\n",
    "normal = load_mode_rows(RESULTS_PATH, 'normal', usecols)\n",
    "\n",
    "num_cols = ['runs','sample_size','element_index','distinct_count','seed'] + metric_cols\n",
    "for c in num_cols:\n",
    "    if c in normal.columns:\n",
    "        normal[c] = pd.to_numeric(normal[c], errors='coerce')\n",
    "\n",
    "print('results:', RESULTS_PATH)\n",
    "print('rows normal:', len(normal))\n",
    "print('sample sizes:', sorted(normal['sample_size'].dropna().unique().tolist()))\n",
    "print('algorithms:', sorted(normal['algorithm'].dropna().unique().tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    'f0_hat_mean','bias','difference','variance','stddev','rmse','mae',\n",
    "    'mean_relative_error','bias_relative','rse_observed','rse_theoretical'\n",
    "]\n",
    "algos = sorted(normal['algorithm'].unique())\n",
    "\n",
    "for metric in metrics:\n",
    "    fig, ax = plt.subplots(figsize=(8.5, 4.8))\n",
    "    for algo in algos:\n",
    "        g = normal[normal['algorithm'] == algo].sort_values('sample_size')\n",
    "        ax.plot(g['sample_size'], g[metric], marker='o', label=algo)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlabel('sample_size')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_title(f'Normal mode: {metric} vs sample_size')\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RSE osservata vs teorica\n",
    "rse_df = normal[np.isfinite(normal['rse_theoretical'])].copy()\n",
    "fig, ax = plt.subplots(figsize=(8.5, 4.8))\n",
    "for algo in sorted(rse_df['algorithm'].unique()):\n",
    "    g = rse_df[rse_df['algorithm'] == algo].sort_values('sample_size')\n",
    "    ax.plot(g['sample_size'], g['rse_observed'], marker='o', label=f'{algo} observed')\n",
    "    ax.plot(g['sample_size'], g['rse_theoretical'], marker='x', linestyle='--', label=f'{algo} theory')\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('sample_size')\n",
    "ax.set_ylabel('RSE')\n",
    "ax.set_title('Normal mode: RSE osservata vs teorica')\n",
    "ax.legend(ncol=2, fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibrazione f0_hat_mean vs f0_mean\n",
    "fig, ax = plt.subplots(figsize=(6.5, 6.0))\n",
    "for algo in sorted(normal['algorithm'].unique()):\n",
    "    g = normal[normal['algorithm'] == algo]\n",
    "    ax.scatter(g['f0_mean'], g['f0_hat_mean'], label=algo)\n",
    "mn = min(normal['f0_mean'].min(), normal['f0_hat_mean'].min())\n",
    "mx = max(normal['f0_mean'].max(), normal['f0_hat_mean'].max())\n",
    "ax.plot([mn, mx], [mn, mx], 'k--', linewidth=1, label='y=x')\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('f0_mean')\n",
    "ax.set_ylabel('f0_hat_mean')\n",
    "ax.set_title('Calibration: f0_hat_mean vs f0_mean')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}